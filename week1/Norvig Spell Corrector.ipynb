{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UfF2dtKEsJPW"
   },
   "source": [
    "# Spell Corrector\n",
    "## Based on Peter Norvig's post at http://norvig.com/spell-correct.html\n",
    "\n",
    "## First, we want a dictionary that tells us how often each word comes up in the English language.\n",
    "To do so, we will:\n",
    "- download a large file that contains the word frequencies from a large corpus of English text\n",
    "- write a small function (get_words) to parse this long text into lines,\n",
    "- compute frequencies\n",
    "- divide by the total number of words to have the frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "9A-tTaL_qU-N"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from collections import defaultdict\n",
    "from pprint import pprint\n",
    "from string import ascii_lowercase as letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "PIn8el5QXWVG"
   },
   "outputs": [],
   "source": [
    "a = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 504,
     "status": "ok",
     "timestamp": 1515576076194,
     "user": {
      "displayName": "Skander Ben Mansour",
      "photoUrl": "//lh5.googleusercontent.com/-cHo8Y2bhcnM/AAAAAAAAAAI/AAAAAAAAyBQ/2NbmEKqWdgY/s50-c-k-no/photo.jpg",
      "userId": "109130222858597057284"
     },
     "user_tz": 0
    },
    "id": "1_xOAkahXvZ-",
    "outputId": "8057d131-94b7-40d3-eea2-4e5ecb2e5424"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "7KaQ6-11Xvlq"
   },
   "outputs": [],
   "source": [
    "a = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "ieB3L-zpsSA-"
   },
   "outputs": [],
   "source": [
    "# someone on the internet already compiled a list of word frequencies\n",
    "# we thank them and download it\n",
    "\n",
    "url = 'http://norvig.com/ngrams/count_1w.txt'\n",
    "\n",
    "big_text = requests.get(url).content.decode('ascii')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 54,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 511,
     "status": "ok",
     "timestamp": 1515576308216,
     "user": {
      "displayName": "Skander Ben Mansour",
      "photoUrl": "//lh5.googleusercontent.com/-cHo8Y2bhcnM/AAAAAAAAAAI/AAAAAAAAyBQ/2NbmEKqWdgY/s50-c-k-no/photo.jpg",
      "userId": "109130222858597057284"
     },
     "user_tz": 0
    },
    "id": "VjGeAhEZ6om-",
    "outputId": "ce189139-4610-422a-d808-a7b82a826197"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the\\t231358'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's look at the first 100 characters of the file\n",
    "\n",
    "big_text[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 137,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 502,
     "status": "ok",
     "timestamp": 1515576359726,
     "user": {
      "displayName": "Skander Ben Mansour",
      "photoUrl": "//lh5.googleusercontent.com/-cHo8Y2bhcnM/AAAAAAAAAAI/AAAAAAAAyBQ/2NbmEKqWdgY/s50-c-k-no/photo.jpg",
      "userId": "109130222858597057284"
     },
     "user_tz": 0
    },
    "id": "5VL9YmOS1QNA",
    "outputId": "c9da4423-f874-49a2-f875-5051f1bb3829"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the\t23135851162\n",
      "of\t13151942776\n",
      "and\t12997637966\n",
      "to\t12136980858\n",
      "a\t9081174698\n",
      "in\t8469404971\n",
      "for\t5933321\n"
     ]
    }
   ],
   "source": [
    "# If we print them, we can see that \\t is tab and \\n is return\n",
    "\n",
    "print(big_text[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "e6JGdYPh0zxT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 the\t23135851162\n",
      "1 of\t13151942776\n",
      "2 and\t12997637966\n",
      "3 to\t12136980858\n",
      "4 a\t9081174698\n",
      "5 in\t8469404971\n",
      "6 for\t5933321709\n",
      "7 is\t4705743816\n",
      "8 on\t3750423199\n",
      "9 that\t3400031103\n"
     ]
    }
   ],
   "source": [
    "# so far, our file is a long string, containing lines of texts\n",
    "# the carriage return character delimits the lines\n",
    "\n",
    "# let's convert this long string into a list of smaller strings, one for each line\n",
    "\n",
    "list_of_lines = big_text.split('\\n')\n",
    "\n",
    "\n",
    "# what are the first 10 items in the list ?\n",
    "\n",
    "for i in range(10):\n",
    "  print(i,list_of_lines[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "ocAoe5ot5YDk"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "333333 \n",
      "333332 golgw\t12711\n",
      "333331 gollgo\t12711\n",
      "333330 gooblle\t12711\n",
      "333329 gooddg\t12711\n",
      "333328 gooek\t12711\n",
      "333327 goofel\t12711\n",
      "333326 googgol\t12711\n",
      "333325 googgoo\t12711\n",
      "333324 googlal\t12711\n"
     ]
    }
   ],
   "source": [
    "# how about the last 10 ?\n",
    "\n",
    "# in python, we can call the last by an index value of -1, the one before using -2, etc.\n",
    "# let's query the last 10 items using this method\n",
    "for i in range(1,11):\n",
    "  item = list_of_lines[-i]\n",
    "  item_position = len(list_of_lines)-i\n",
    "  print(item_position,item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "6zr_pX-c5pRy"
   },
   "outputs": [],
   "source": [
    "# it looks like the last line is empty : let's get rid of it\n",
    "\n",
    "list_of_lines = list_of_lines[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "HsHMxprq15_0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the\\t23135851162'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# each item in the list is now a word followed by the word frequency\n",
    "\n",
    "# this looks like this\n",
    "list_of_lines[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "zP7hPmZM2NIG"
   },
   "outputs": [],
   "source": [
    "# let's write a function that takes this line and returns a word (string) and the frequency (integer)\n",
    "\n",
    "def process_line(line):\n",
    "  '''\n",
    "  Input: string\n",
    "  Output: tuple(string,integer)\n",
    "  '''\n",
    "  word,frequency = line.split('\\t')\n",
    "  frequency = int(frequency)\n",
    "  return word,frequency\n",
    "\n",
    "\n",
    "# let's test the function\n",
    "\n",
    "assert process_line('the\\t123') == ('the',123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "CIFqbi4i3Ijz"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('by', 3350048871)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's run the function on one of our lines\n",
    "# we can see it returns 2 items as expected, a tuple\n",
    "\n",
    "process_line(list_of_lines[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "Eqdy4d0j0daw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{} 0\n"
     ]
    }
   ],
   "source": [
    "# now we can create an empty dictionary : words_dict\n",
    "# the keys of the dictionary will be words and the values associated to each keys the word frequencies\n",
    "\n",
    "words_dict = dict()\n",
    "\n",
    "# let's print the dictionary content (empty) and number of keys so far (0, none)\n",
    "\n",
    "print(words_dict, len(words_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "hg8i8UTE3a2O"
   },
   "outputs": [],
   "source": [
    "# we can iterate through our list\n",
    "# for each line, we call the processing function\n",
    "# we then use the result to update our dictionary words_dict\n",
    "\n",
    "for line in list_of_lines:\n",
    "  # python uses indentation to define what goes into the 'for' loop, rather than brackets\n",
    "\n",
    "  # we now use python pattern matching to recognise that\n",
    "  # 1. the function returns 2 elements in a tuple\n",
    "  # 2. we can therefore assign one to each of the variables on the left\n",
    "  word,count = process_line(line)\n",
    "  \n",
    "  # we update the dictionary for this line\n",
    "  words_dict[word] = count\n",
    "  \n",
    "  # end of the for loop - we continue to the next line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 23135851162),\n",
       " ('of', 13151942776),\n",
       " ('and', 12997637966),\n",
       " ('to', 12136980858),\n",
       " ('a', 9081174698),\n",
       " ('in', 8469404971),\n",
       " ('for', 5933321709),\n",
       " ('is', 4705743816),\n",
       " ('on', 3750423199),\n",
       " ('that', 3400031103)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(map(process_line,list_of_lines))[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 4, 9]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=[1,2,3]\n",
    "def square(x):\n",
    "    return(x**2)\n",
    "b= [square(i) for i in a]\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 4, 9]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(map(square,a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "be9MnFWX4pIe"
   },
   "outputs": [],
   "source": [
    "# interestingly, what we just did can be defined in a one liner\n",
    "# we map a function to each element of the list\n",
    "# we iterate through the list of results and build a dictionary using list comprehension\n",
    "\n",
    "words_dict = {word:count for word,count in map(process_line,list_of_lines)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "4pa-avEq6N_r"
   },
   "outputs": [],
   "source": [
    "# even simpler, by directly constructing the dictionary, based on the list of (key,value) tuples\n",
    "\n",
    "words_dict = dict(map(process_line,list_of_lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "mVyW-jkY7MPQ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'key 1': 123, 'key 2': 321}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is the same as doing\n",
    "\n",
    "simple_dict = dict( [('key 1',123),\n",
    "                     ('key 2',321)\n",
    "                    ]\n",
    "                  )\n",
    "\n",
    "simple_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "NWi0Vjzq7nbf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "By Keys\n",
      "key 1\n",
      "key 2\n",
      "\n",
      "By Values\n",
      "123\n",
      "321\n",
      "\n",
      "By Items (both keys and values)\n",
      "('key 1', 123)\n",
      "key 1\n",
      "key 1\n",
      "('key 2', 321)\n",
      "key 2\n",
      "key 2\n"
     ]
    }
   ],
   "source": [
    "# we can iterate through the dictionary by keys, values, or items (both)\n",
    "\n",
    "print('\\nBy Keys')\n",
    "for key in simple_dict.keys():\n",
    "  print(key)\n",
    "\n",
    "print('\\nBy Values')\n",
    "for value in simple_dict.values():\n",
    "  print(value)\n",
    "\n",
    "print('\\nBy Items (both keys and values)')\n",
    "for key_value_pair in simple_dict.items():\n",
    "  # key_value_pair is a tuple\n",
    "  print(key_value_pair)\n",
    "  # we can access each element of the tuple\n",
    "  print(key_value_pair[0])\n",
    "  # we can use pattern matching to split the tuple into separate variables\n",
    "  key,value = key_value_pair\n",
    "  print(key)\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "mlDjlIALroJF"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23135851162"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the words_dict dictionary has word as keys and counts as values\n",
    "# we can lookup the number of time any word has been seen in the dataset\n",
    "\n",
    "words_dict['the']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "fMgLKFintZbQ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "588124220187\n"
     ]
    }
   ],
   "source": [
    "# how many words are there in the dataset ?\n",
    "\n",
    "# we take the sum of the dictionary values\n",
    "total_count = sum(words_dict.values())\n",
    "print(total_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "IFzvd8__rRt8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "333333\n"
     ]
    }
   ],
   "source": [
    "# we can now compute the frequencies of occurence, by dividing the count of each word by the total number of occurences\n",
    "# we do so using dictionary comprehension\n",
    "\n",
    "words_freq = {word:count/total_count for word,count in words_dict.items()}\n",
    "print(len(words_freq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "sg8PC6eRvnBc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03933837507090547"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the words_freq dictionary has word as keys and frequencies as values\n",
    "# we can lookup the frequency of any word has been seen in the dataset\n",
    "\n",
    "words_freq['the']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9Jq1XKQ2ysS5"
   },
   "source": [
    "# We are now ready to build our Spell Checker\n",
    "\n",
    "## Let's define what we want to build:\n",
    "\n",
    "- Input : a word provided by the user, and potentially mispelled\n",
    "- Output : the word most likely intended by the user\n",
    "\n",
    "## We will use a bayesian approach:\n",
    "\n",
    "This means that the probability that the user meant word X when they typed word W is:\n",
    "1. the base probability (frequency) of the candidate words X in English\n",
    "2. adjusted by the probability that the user would type W, when they meant X\n",
    "3. normalised by the overall probability of word W\n",
    "\n",
    "We can then choose the candidate word X that maximises the probability $ P(meansX \\mid typesW) $\n",
    "\n",
    "## Bayes' theorem\n",
    "\n",
    "$ P(meantX \\mid typesW) = P(meantX) \\frac{P(typesW \\mid meantX)}{P(typesW)} $\n",
    "\n",
    "## How we are going to do this\n",
    "\n",
    "1. The base probability is already given by our words_freq dictionary\n",
    "2. We need to define the types of errors that the user could have done when typing\n",
    "3. This normalisation factor is the same for all the candidate words, so will apply to all candidates in exactly the same way. That means we can then ignore it!\n",
    "\n",
    "# Let's start with computing the base probability\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "q0uqziscNiUN"
   },
   "outputs": [],
   "source": [
    "# we already know the base probability of each word\n",
    "\n",
    "def get_base_probability(meantX):\n",
    "  return words_freq[meantX]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "apIBODGwNtEF"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03933837507090547"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_base_probability('the')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "loQ8fAC8Nwol"
   },
   "outputs": [],
   "source": [
    "def is_known(word):\n",
    "  return word in words_freq\n",
    "\n",
    "\n",
    "# some tests\n",
    "assert is_known('the')\n",
    "assert not is_known('fsdjfgsdhjgf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "ppAC_hIROHtk"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               hello : True\n",
      "                   i : True\n",
      "                  am : True\n",
      "             skander : False\n"
     ]
    }
   ],
   "source": [
    "# let's test for known words\n",
    "\n",
    "for word in 'Hello I am Skander'.lower().split(' '):\n",
    "  word_is_known = is_known(word)\n",
    "  print('%20s : %s' % (word,word_is_known))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hWnQoV1F9uUz"
   },
   "source": [
    "## Now we need a function that can return candidates (plausible variations/typos) for any given typed word\n",
    "\n",
    "We will do this by:\n",
    "- Defining a list of places in the typed word where thing could have gone wrong\n",
    "- Try out all possible errors in all possible places, assigning to each typo a score (probability) based on how likely it is to occur\n",
    "- We repeat this several times, which gives us the possible typos from typos, typos from typos from typos etc\n",
    "- For each, we will get a score that reflects how likely this is to happen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "D8Cqp49eQWdD"
   },
   "outputs": [],
   "source": [
    "def get_splits(word):\n",
    "  '''returns all the places in the word where something can go wrong'''\n",
    "  return [(word[:i], word[i:]) for i in range(len(word) + 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "ozzktqarR4wT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('', 'hello'),\n",
      " ('h', 'ello'),\n",
      " ('he', 'llo'),\n",
      " ('hel', 'lo'),\n",
      " ('hell', 'o'),\n",
      " ('hello', '')]\n"
     ]
    }
   ],
   "source": [
    "splits = get_splits('hello')\n",
    "pprint(splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "TzFEIukITxA3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('', 'hello')\n",
      "('h', 'ello')\n",
      "('he', 'llo')\n",
      "('hel', 'lo')\n",
      "('hell', 'o')\n",
      "('hello', '')\n"
     ]
    }
   ],
   "source": [
    "# let's iterate through the splits:\n",
    "\n",
    "for split in splits:\n",
    "  print(split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "eXD4kPuQT3I-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"hello\" \"\"\n",
      "\"ello\" \"h\"\n",
      "\"llo\" \"he\"\n",
      "\"lo\" \"hel\"\n",
      "\"o\" \"hell\"\n",
      "\"\" \"hello\"\n"
     ]
    }
   ],
   "source": [
    "# since each split is made up of 2 part, we can again use Python's pattern matching abilities\n",
    "# let's invert left and right for fun\n",
    "\n",
    "for left,right in splits:\n",
    "  print('\"%s\" \"%s\"' % (right,left))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "OmII2vt7QWWR"
   },
   "outputs": [],
   "source": [
    "# so what can get wrong, for each split ?\n",
    "\n",
    "# 1. the user may forget to type a letter\n",
    "\n",
    "DELETE_SCORE = 0.1\n",
    "def get_deletes(splits):\n",
    "  '''Removes a character from the right part of the split'''\n",
    "  deletes = [L + R[1:] for L, R in splits if R]\n",
    "  return DELETE_SCORE,deletes\n",
    "\n",
    "# testing it works\n",
    "assert get_deletes([('hel','lo')])[1] == [('helo')]\n",
    "\n",
    "\n",
    "# 2. the user may swap 2 letters\n",
    "\n",
    "TRANSPOSE_SCORE = 0.1\n",
    "def get_transposes(splits):\n",
    "  '''Exchanges the first 2 characters of the right part of the split'''\n",
    "  transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R)>1]\n",
    "  return TRANSPOSE_SCORE,transposes\n",
    "\n",
    "# testing it works\n",
    "assert get_transposes([('hel','lo')])[1] == [('helol')]\n",
    "\n",
    "\n",
    "# 3. the user may replace a letter by another random one\n",
    "\n",
    "REPLACE_SCORE = 0.1\n",
    "def get_replaces(splits):\n",
    "  '''Replaces the first letter of the right part of the split by all possible letters from the alphabet'''\n",
    "  replaces = [L + c + R[1:] for L, R in splits if R for c in letters]\n",
    "  return REPLACE_SCORE,replaces\n",
    "\n",
    "# 3. the user may insert a random letter\n",
    "\n",
    "INSERT_SCORE = 0.1\n",
    "def get_inserts(splits):\n",
    "  '''Inserts all possible letters between the two parts of the split'''\n",
    "  inserts = [L + c + R for L, R in splits for c in letters]\n",
    "  return INSERT_SCORE,inserts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "wAPXwoVeR4yl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_deletes\n",
      "Removes a character from the right part of the split\n",
      "0.1\n",
      "['an', 'mn', 'ma']\n",
      "\n",
      "get_transposes\n",
      "Exchanges the first 2 characters of the right part of the split\n",
      "0.1\n",
      "['amn', 'mna']\n",
      "\n",
      "get_inserts\n",
      "Inserts all possible letters between the two parts of the split\n",
      "0.1\n",
      "['aman',\n",
      " 'bman',\n",
      " 'cman',\n",
      " 'dman',\n",
      " 'eman',\n",
      " 'fman',\n",
      " 'gman',\n",
      " 'hman',\n",
      " 'iman',\n",
      " 'jman',\n",
      " 'kman',\n",
      " 'lman',\n",
      " 'mman',\n",
      " 'nman',\n",
      " 'oman',\n",
      " 'pman',\n",
      " 'qman',\n",
      " 'rman',\n",
      " 'sman',\n",
      " 'tman',\n",
      " 'uman',\n",
      " 'vman',\n",
      " 'wman',\n",
      " 'xman',\n",
      " 'yman',\n",
      " 'zman',\n",
      " 'maan',\n",
      " 'mban',\n",
      " 'mcan',\n",
      " 'mdan',\n",
      " 'mean',\n",
      " 'mfan',\n",
      " 'mgan',\n",
      " 'mhan',\n",
      " 'mian',\n",
      " 'mjan',\n",
      " 'mkan',\n",
      " 'mlan',\n",
      " 'mman',\n",
      " 'mnan',\n",
      " 'moan',\n",
      " 'mpan',\n",
      " 'mqan',\n",
      " 'mran',\n",
      " 'msan',\n",
      " 'mtan',\n",
      " 'muan',\n",
      " 'mvan',\n",
      " 'mwan',\n",
      " 'mxan']\n",
      "\n",
      "get_replaces\n",
      "Replaces the first letter of the right part of the split by all possible letters from the alphabet\n",
      "0.1\n",
      "['aan',\n",
      " 'ban',\n",
      " 'can',\n",
      " 'dan',\n",
      " 'ean',\n",
      " 'fan',\n",
      " 'gan',\n",
      " 'han',\n",
      " 'ian',\n",
      " 'jan',\n",
      " 'kan',\n",
      " 'lan',\n",
      " 'man',\n",
      " 'nan',\n",
      " 'oan',\n",
      " 'pan',\n",
      " 'qan',\n",
      " 'ran',\n",
      " 'san',\n",
      " 'tan',\n",
      " 'uan',\n",
      " 'van',\n",
      " 'wan',\n",
      " 'xan',\n",
      " 'yan',\n",
      " 'zan',\n",
      " 'man',\n",
      " 'mbn',\n",
      " 'mcn',\n",
      " 'mdn',\n",
      " 'men',\n",
      " 'mfn',\n",
      " 'mgn',\n",
      " 'mhn',\n",
      " 'min',\n",
      " 'mjn',\n",
      " 'mkn',\n",
      " 'mln',\n",
      " 'mmn',\n",
      " 'mnn',\n",
      " 'mon',\n",
      " 'mpn',\n",
      " 'mqn',\n",
      " 'mrn',\n",
      " 'msn',\n",
      " 'mtn',\n",
      " 'mun',\n",
      " 'mvn',\n",
      " 'mwn',\n",
      " 'mxn']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# for fun: let's create a list of functions and iterate through it\n",
    "\n",
    "# this is a list of functions !\n",
    "my_typo_generating_functions = [get_deletes,get_transposes,get_inserts,get_replaces]\n",
    "\n",
    "#we will apply each one to the possible splits of 'man'\n",
    "splits = get_splits('man')\n",
    "\n",
    "\n",
    "for my_function in my_typo_generating_functions:\n",
    "  # let's print the function name and documentation\n",
    "  print(my_function.__name__)\n",
    "  print(my_function.__doc__)\n",
    "  \n",
    "  # let's apply the function\n",
    "  score,potential_typos = my_function(splits)\n",
    "  print(score)\n",
    "  \n",
    "  # let's print the first 50 results\n",
    "  pprint(potential_typos[:50])\n",
    "  print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "D7-kjsWkcFek"
   },
   "outputs": [],
   "source": [
    "# so, given a word, what could go wrong and how likely is it ?\n",
    "\n",
    "CHANGE_NOTHING_SCORE = 1\n",
    "def get_simple_typos(word):\n",
    "  \n",
    "  # first, it is possible that nothing goes wrong and the user types what they intended\n",
    "  yield word,CHANGE_NOTHING_SCORE\n",
    "  # yield is not the same as return, it means the function will return a list / iterable\n",
    "  # we will tell the function which items to include in the list, one after the other\n",
    "  # here, we start with the initial word, unmodified\n",
    "  \n",
    "  # now, let's figure out possible typos:\n",
    "  splits = get_splits(word)\n",
    "  \n",
    "  # now we try out / iterate through all possible ways to make typos\n",
    "  for my_function in my_typo_generating_functions:\n",
    "    # we apply each function to the splits\n",
    "    score, typos = my_function(splits)\n",
    "    # for each result, we yield the typo, and score\n",
    "    for typo in typos:\n",
    "      yield typo,score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "ieQZjX9GedAe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 man : 1.0000\n",
      "                  an : 0.1000\n",
      "                  mn : 0.1000\n",
      "                  ma : 0.1000\n",
      "                 amn : 0.1000\n",
      "                 mna : 0.1000\n",
      "                aman : 0.1000\n",
      "                bman : 0.1000\n",
      "                cman : 0.1000\n",
      "                dman : 0.1000\n",
      "                eman : 0.1000\n",
      "                fman : 0.1000\n",
      "                gman : 0.1000\n",
      "                hman : 0.1000\n",
      "                iman : 0.1000\n",
      "                jman : 0.1000\n",
      "                kman : 0.1000\n",
      "                lman : 0.1000\n",
      "                mman : 0.1000\n",
      "                nman : 0.1000\n",
      "                oman : 0.1000\n",
      "                pman : 0.1000\n",
      "                qman : 0.1000\n",
      "                rman : 0.1000\n",
      "                sman : 0.1000\n",
      "                tman : 0.1000\n",
      "                uman : 0.1000\n",
      "                vman : 0.1000\n",
      "                wman : 0.1000\n",
      "                xman : 0.1000\n",
      "                yman : 0.1000\n",
      "                zman : 0.1000\n",
      "                maan : 0.1000\n",
      "                mban : 0.1000\n",
      "                mcan : 0.1000\n",
      "                mdan : 0.1000\n",
      "                mean : 0.1000\n",
      "                mfan : 0.1000\n",
      "                mgan : 0.1000\n",
      "                mhan : 0.1000\n",
      "                mian : 0.1000\n",
      "                mjan : 0.1000\n",
      "                mkan : 0.1000\n",
      "                mlan : 0.1000\n",
      "                mman : 0.1000\n",
      "                mnan : 0.1000\n",
      "                moan : 0.1000\n",
      "                mpan : 0.1000\n",
      "                mqan : 0.1000\n",
      "                mran : 0.1000\n",
      "                msan : 0.1000\n",
      "                mtan : 0.1000\n",
      "                muan : 0.1000\n",
      "                mvan : 0.1000\n",
      "                mwan : 0.1000\n",
      "                mxan : 0.1000\n",
      "                myan : 0.1000\n",
      "                mzan : 0.1000\n",
      "                maan : 0.1000\n",
      "                mabn : 0.1000\n",
      "                macn : 0.1000\n",
      "                madn : 0.1000\n",
      "                maen : 0.1000\n",
      "                mafn : 0.1000\n",
      "                magn : 0.1000\n",
      "                mahn : 0.1000\n",
      "                main : 0.1000\n",
      "                majn : 0.1000\n",
      "                makn : 0.1000\n",
      "                maln : 0.1000\n",
      "                mamn : 0.1000\n",
      "                mann : 0.1000\n",
      "                maon : 0.1000\n",
      "                mapn : 0.1000\n",
      "                maqn : 0.1000\n",
      "                marn : 0.1000\n",
      "                masn : 0.1000\n",
      "                matn : 0.1000\n",
      "                maun : 0.1000\n",
      "                mavn : 0.1000\n",
      "                mawn : 0.1000\n",
      "                maxn : 0.1000\n",
      "                mayn : 0.1000\n",
      "                mazn : 0.1000\n",
      "                mana : 0.1000\n",
      "                manb : 0.1000\n",
      "                manc : 0.1000\n",
      "                mand : 0.1000\n",
      "                mane : 0.1000\n",
      "                manf : 0.1000\n",
      "                mang : 0.1000\n",
      "                manh : 0.1000\n",
      "                mani : 0.1000\n",
      "                manj : 0.1000\n",
      "                mank : 0.1000\n",
      "                manl : 0.1000\n",
      "                manm : 0.1000\n",
      "                mann : 0.1000\n",
      "                mano : 0.1000\n",
      "                manp : 0.1000\n",
      "                manq : 0.1000\n",
      "                manr : 0.1000\n",
      "                mans : 0.1000\n",
      "                mant : 0.1000\n",
      "                manu : 0.1000\n",
      "                manv : 0.1000\n",
      "                manw : 0.1000\n",
      "                manx : 0.1000\n",
      "                many : 0.1000\n",
      "                manz : 0.1000\n",
      "                 aan : 0.1000\n",
      "                 ban : 0.1000\n",
      "                 can : 0.1000\n",
      "                 dan : 0.1000\n",
      "                 ean : 0.1000\n",
      "                 fan : 0.1000\n",
      "                 gan : 0.1000\n",
      "                 han : 0.1000\n",
      "                 ian : 0.1000\n",
      "                 jan : 0.1000\n",
      "                 kan : 0.1000\n",
      "                 lan : 0.1000\n",
      "                 man : 0.1000\n",
      "                 nan : 0.1000\n",
      "                 oan : 0.1000\n",
      "                 pan : 0.1000\n",
      "                 qan : 0.1000\n",
      "                 ran : 0.1000\n",
      "                 san : 0.1000\n",
      "                 tan : 0.1000\n",
      "                 uan : 0.1000\n",
      "                 van : 0.1000\n",
      "                 wan : 0.1000\n",
      "                 xan : 0.1000\n",
      "                 yan : 0.1000\n",
      "                 zan : 0.1000\n",
      "                 man : 0.1000\n",
      "                 mbn : 0.1000\n",
      "                 mcn : 0.1000\n",
      "                 mdn : 0.1000\n",
      "                 men : 0.1000\n",
      "                 mfn : 0.1000\n",
      "                 mgn : 0.1000\n",
      "                 mhn : 0.1000\n",
      "                 min : 0.1000\n",
      "                 mjn : 0.1000\n",
      "                 mkn : 0.1000\n",
      "                 mln : 0.1000\n",
      "                 mmn : 0.1000\n",
      "                 mnn : 0.1000\n",
      "                 mon : 0.1000\n",
      "                 mpn : 0.1000\n",
      "                 mqn : 0.1000\n",
      "                 mrn : 0.1000\n",
      "                 msn : 0.1000\n",
      "                 mtn : 0.1000\n",
      "                 mun : 0.1000\n",
      "                 mvn : 0.1000\n",
      "                 mwn : 0.1000\n",
      "                 mxn : 0.1000\n",
      "                 myn : 0.1000\n",
      "                 mzn : 0.1000\n",
      "                 maa : 0.1000\n",
      "                 mab : 0.1000\n",
      "                 mac : 0.1000\n",
      "                 mad : 0.1000\n",
      "                 mae : 0.1000\n",
      "                 maf : 0.1000\n",
      "                 mag : 0.1000\n",
      "                 mah : 0.1000\n",
      "                 mai : 0.1000\n",
      "                 maj : 0.1000\n",
      "                 mak : 0.1000\n",
      "                 mal : 0.1000\n",
      "                 mam : 0.1000\n",
      "                 man : 0.1000\n",
      "                 mao : 0.1000\n",
      "                 map : 0.1000\n",
      "                 maq : 0.1000\n",
      "                 mar : 0.1000\n",
      "                 mas : 0.1000\n",
      "                 mat : 0.1000\n",
      "                 mau : 0.1000\n",
      "                 mav : 0.1000\n",
      "                 maw : 0.1000\n",
      "                 max : 0.1000\n",
      "                 may : 0.1000\n",
      "                 maz : 0.1000\n"
     ]
    }
   ],
   "source": [
    "for typo,score in get_simple_typos('man'):\n",
    "  print('%20s : %5.4f' % (typo,score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "Es5LyoHQSrST"
   },
   "outputs": [],
   "source": [
    "MAXIMUM_NUMBER_OF_TYPOS = 2\n",
    "\n",
    "def get_complex_typos(word):\n",
    "  # here we will want to keep track of how often every typo can come up, in a typos dictionary\n",
    "  # note that they may come up multiple times, as the user can make several mistakes / undo them\n",
    "  \n",
    "  # default dictionary behave like normal dictionaries, except that they have a default value (here 0)\n",
    "  typos = defaultdict(int)\n",
    "  \n",
    "  # so far we only have our initial word, that came up once\n",
    "  typos[word] = 1\n",
    "  \n",
    "  # let's allow the user to make a given number of typos\n",
    "  for _ in range(MAXIMUM_NUMBER_OF_TYPOS):\n",
    "    \n",
    "    # we will create all possible variations from the current set of typos\n",
    "    current_set_of_typos = list(typos.items())\n",
    "    # we iterate through this list of key,value pairs\n",
    "    for typo,score in current_set_of_typos:\n",
    "      # we get for each typo, a list of variations and how likely they are to happen\n",
    "      for new_typo,new_score in get_simple_typos(typo):\n",
    "        # we update the dictionary with the new score\n",
    "        typos[new_typo] += score * new_score\n",
    "  return typos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "9AxzBuCVeZ35"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 man : 7.1900\n",
      "                maan : 1.5200\n",
      "                mman : 1.4900\n",
      "                mann : 1.4900\n",
      "                mnan : 0.8000\n",
      "                mamn : 0.8000\n",
      "                mban : 0.7800\n",
      "                mcan : 0.7800\n",
      "                mdan : 0.7800\n",
      "                mean : 0.7800\n",
      "                mfan : 0.7800\n",
      "                mgan : 0.7800\n",
      "                mhan : 0.7800\n",
      "                mian : 0.7800\n",
      "                mjan : 0.7800\n",
      "                mkan : 0.7800\n",
      "                mlan : 0.7800\n",
      "                moan : 0.7800\n",
      "                mpan : 0.7800\n",
      "                mqan : 0.7800\n"
     ]
    }
   ],
   "source": [
    "complex_typos = get_complex_typos('man')\n",
    "\n",
    "most_common_typos = sorted(complex_typos,\n",
    "                           key=lambda typo:complex_typos[typo],\n",
    "                           reverse=True)\n",
    "\n",
    "for typo in most_common_typos[:20]:\n",
    "  print('%20s : %5.4f' % (typo,complex_typos[typo]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "UGUgHmt3OH0D"
   },
   "outputs": [],
   "source": [
    "# notice above that\n",
    "# - the score do not add up to one (they are not expected to)\n",
    "# - it would be handy to easy print the top ranking candidates in the future\n",
    "\n",
    "# to that end : we create some helper functions : one to normalise and one to show the top ranked\n",
    "\n",
    "def normalise(scores):\n",
    "  total_scores = sum(scores.values())\n",
    "  return {item:score/total_scores for item,score in scores.items()}\n",
    "\n",
    "# notice the default parameter value : this means we can ommit top when calling the function\n",
    "def show_best(scores,top=10):\n",
    "  for word in sorted(scores,key=lambda x: scores[x],reverse=True)[:top]:\n",
    "    print('%20s : %5.4f%%' % (word,100*scores[word]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "u9-02TA2Ic2-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 man : 1.4885%\n",
      "                maan : 0.3147%\n",
      "                mman : 0.3085%\n",
      "                mann : 0.3085%\n",
      "                mnan : 0.1656%\n",
      "                mamn : 0.1656%\n",
      "                mban : 0.1615%\n",
      "                mcan : 0.1615%\n",
      "                mdan : 0.1615%\n",
      "                mean : 0.1615%\n"
     ]
    }
   ],
   "source": [
    "show_best(normalise(get_complex_typos('man')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "l_q_Me4TIJvV"
   },
   "outputs": [],
   "source": [
    "def get_candidates(word):\n",
    "  # we will only return as candidates typos that are actually in the dictionary (is_known)\n",
    "  candidates = {typo:score for typo,score in get_complex_typos(word).items() if is_known(typo)}\n",
    "  return normalise(candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "m0Eie3gegimx"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 man : 3.8359%\n",
      "                maan : 0.8109%\n",
      "                mman : 0.7949%\n",
      "                mann : 0.7949%\n",
      "                mean : 0.4161%\n",
      "                mian : 0.4161%\n",
      "                mlan : 0.4161%\n",
      "                moan : 0.4161%\n",
      "                maen : 0.4161%\n",
      "                magn : 0.4161%\n"
     ]
    }
   ],
   "source": [
    "# so, which are the highest scoring candidates, meaning the typos that actually exist in English ?\n",
    "# remember that this has not yet been adjusted by the base probability\n",
    "\n",
    "show_best(get_candidates('man'))\n",
    "\n",
    "# we can also see that our English dataset contains some weird words ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "13MGQrM3Goob"
   },
   "source": [
    "## We are now ready to wrap it up:\n",
    "\n",
    "We have:\n",
    "- the base probability for each word\n",
    "- an adjustement based on how likely each word is to be meant by the user, given what they typed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "dwaVvkKxOH4c"
   },
   "outputs": [],
   "source": [
    "# we can compute the adjusted score for each word\n",
    "\n",
    "def get_likelihood(word):\n",
    "  # we get the score for each candidate\n",
    "  candidates = get_candidates(word)\n",
    "  # we build a dictionary containing the base probability, adjusted by the score, for each candidate  \n",
    "  likelihood = {candidate:score * get_base_probability(candidate)\n",
    "                for candidate,score in candidates.items()}\n",
    "  return normalise(likelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "dVI4NdrLhwAr"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 man : 17.9775%\n",
      "                  an : 15.2730%\n",
      "                 can : 12.4972%\n",
      "                 may : 8.3275%\n",
      "                  in : 4.6684%\n",
      "                 jan : 3.6862%\n",
      "                 and : 3.5822%\n",
      "                many : 3.2966%\n",
      "                 map : 3.1152%\n",
      "                   a : 2.5028%\n",
      "                main : 2.1456%\n",
      "                  on : 2.0673%\n",
      "                 men : 1.7509%\n",
      "                 san : 1.5225%\n",
      "                 mar : 1.0382%\n",
      "                mean : 0.8632%\n",
      "                 mon : 0.7286%\n",
      "                  at : 0.6262%\n",
      "                  as : 0.6194%\n",
      "                  ma : 0.5926%\n"
     ]
    }
   ],
   "source": [
    "show_best(get_likelihood('man'),top=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "wHhJRMX7JHbr"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              shrimp : 42.0021%\n",
      "              script : 23.8049%\n",
      "               crime : 9.8393%\n",
      "               crimp : 6.1699%\n",
      "               strip : 4.5614%\n",
      "               scrip : 3.2866%\n",
      "              scrimp : 3.1795%\n",
      "               scrap : 1.8318%\n",
      "               scrim : 1.4143%\n",
      "               crisp : 0.9460%\n"
     ]
    }
   ],
   "source": [
    "# let's see how the base probabilities in our dataset can influence the corrections\n",
    "\n",
    "show_best(get_likelihood('scrimp'),top=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "xO8XLAEqqoDr"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hell': 3.8753520459934624e-05,\n",
      " 'help': 0.0010389880454263715,\n",
      " 'well': 0.0006156569353407553}\n"
     ]
    }
   ],
   "source": [
    "pprint({word:get_base_probability(word) for word in ['help','well','hell']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "giAKzUQR5h57"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "Norvig Spell Corrector.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
